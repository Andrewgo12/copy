# Gu√≠a de Instalaci√≥n Completa

## Requisitos del Sistema

### Requisitos M√≠nimos
- **Python**: 3.8 o superior (recomendado 3.11)
- **RAM**: 4GB m√≠nimo, 8GB recomendado
- **Almacenamiento**: 2GB libres para datos y modelos
- **CPU**: 2 cores m√≠nimo, 4+ cores recomendado
- **SO**: Windows 10+, macOS 10.15+, Ubuntu 18.04+

### Requisitos Opcionales
- **Docker**: Para sandboxing avanzado
- **Git**: Para operaciones de control de versiones
- **Node.js**: Para herramientas de JavaScript
- **CUDA**: Para aceleraci√≥n GPU (modelos locales)

## Instalaci√≥n Paso a Paso

### 1. Preparaci√≥n del Entorno

```bash
# Clonar el repositorio
git clone https://github.com/tu-usuario/local-agent.git
cd local-agent

# Crear entorno virtual
python -m venv venv

# Activar entorno virtual
# En Windows:
venv\Scripts\activate
# En macOS/Linux:
source venv/bin/activate

# Verificar versi√≥n de Python
python --version  # Debe ser 3.8+
```

### 2. Instalaci√≥n de Dependencias

```bash
# Actualizar pip
pip install --upgrade pip

# Instalar dependencias principales
pip install -r requirements.txt

# Verificar instalaci√≥n
python -c "import langchain, chromadb, fastapi; print('‚úÖ Dependencias instaladas')"
```

### 3. Configuraci√≥n Inicial

```bash
# Copiar archivo de configuraci√≥n
cp .env.example .env

# Editar configuraci√≥n (ver secci√≥n de configuraci√≥n)
nano .env  # o tu editor preferido
```

### 4. Configuraci√≥n de APIs

#### OpenAI (Recomendado)
1. Crear cuenta en [OpenAI](https://platform.openai.com/)
2. Generar API key en la secci√≥n API keys
3. A√±adir a `.env`:
```bash
OPENAI_API_KEY=sk-tu-clave-aqui
LLM_PROVIDER=openai
LLM_MODEL=gpt-4
```

#### Anthropic (Alternativa)
1. Crear cuenta en [Anthropic](https://console.anthropic.com/)
2. Generar API key
3. A√±adir a `.env`:
```bash
ANTHROPIC_API_KEY=tu-clave-anthropic
LLM_PROVIDER=anthropic
LLM_MODEL=claude-3-sonnet-20240229
```

#### Modelos Locales (Avanzado)
```bash
# Instalar dependencias adicionales
pip install transformers torch accelerate

# Configurar en .env
LLM_PROVIDER=local
LLM_MODEL=microsoft/DialoGPT-medium
```

### 5. Inicializaci√≥n de la Base de Datos

```bash
# Ejecutar setup inicial
python -m local_agent.interfaces.cli setup

# Verificar que se crearon los directorios
ls -la data/
# Deber√≠a mostrar: vector_db/, cache/, logs/, backups/
```

### 6. Verificaci√≥n de la Instalaci√≥n

```bash
# Test b√°sico
python main.py --test

# Test interactivo
python -m local_agent.interfaces.cli interactive

# Test de herramientas
python -c "
from local_agent.core.agent import create_agent
import asyncio

async def test():
    agent = create_agent()
    tools = await agent.get_available_tools()
    print(f'‚úÖ {len(tools)} herramientas disponibles')
    await agent.shutdown()

asyncio.run(test())
"
```

## Instalaci√≥n con Docker

### Opci√≥n 1: Docker Compose (Recomendado)

```bash
# Clonar repositorio
git clone https://github.com/tu-usuario/local-agent.git
cd local-agent

# Configurar variables de entorno
cp .env.example .env
# Editar .env con tus claves API

# Iniciar todos los servicios
docker-compose up -d

# Verificar que los servicios est√°n corriendo
docker-compose ps

# Ver logs
docker-compose logs -f local-agent
```

### Opci√≥n 2: Docker Manual

```bash
# Construir imagen
docker build -t local-agent .

# Ejecutar contenedor
docker run -d \
  --name local-agent \
  -p 8000:8000 \
  -p 8501:8501 \
  -v $(pwd)/data:/app/data \
  -e OPENAI_API_KEY=tu-clave \
  local-agent
```

## Configuraci√≥n Detallada

### Archivo .env Principal

```bash
# =============================================================================
# CONFIGURACI√ìN ESENCIAL
# =============================================================================

# API Keys (REQUERIDO)
OPENAI_API_KEY=sk-tu-clave-openai-aqui
ANTHROPIC_API_KEY=tu-clave-anthropic-aqui

# Configuraci√≥n del modelo
LLM_PROVIDER=openai          # openai, anthropic, local
LLM_MODEL=gpt-4             # gpt-4, gpt-3.5-turbo, claude-3-sonnet
MAX_ITERATIONS=10

# Configuraci√≥n de seguridad
ENABLE_SANDBOX=true
REQUIRE_CONFIRMATION=true
MAX_EXECUTION_TIME=300

# Configuraci√≥n de memoria
ENABLE_MEMORY=true
MEMORY_IMPORTANCE_THRESHOLD=0.3

# Configuraci√≥n de logging
LOG_LEVEL=INFO
LOG_FILE=./data/logs/agent.log
```

### Configuraci√≥n Avanzada de Herramientas

```yaml
# config/tools.yml
tools:
  file_operations:
    enabled: true
    max_file_size: "10MB"
    allowed_extensions: [".txt", ".py", ".js", ".md", ".json", ".yml"]
    blocked_paths: ["/etc", "/sys", "/proc", "C:\\Windows"]
    
  system_commands:
    enabled: true
    sandbox_required: true
    timeout: 60
    blocked_commands:
      - "rm -rf"
      - "del /s"
      - "format"
      - "shutdown"
      - "reboot"
    allowed_commands:
      - "ls"
      - "dir" 
      - "python"
      - "node"
      - "git"
    
  web_tools:
    enabled: true
    max_requests_per_minute: 10
    timeout: 30
    blocked_domains:
      - "malware.com"
      - "phishing.net"
    user_agent: "LocalAgent/1.0"
    
  code_analysis:
    enabled: true
    supported_languages: ["python", "javascript", "typescript", "java", "cpp"]
    max_file_size: "5MB"
    enable_syntax_checking: true
    enable_security_scanning: true
```

### Configuraci√≥n de Seguridad Avanzada

```yaml
# config/security.yml
security:
  guardrails:
    enabled: true
    strict_mode: false
    custom_rules:
      - name: "protect_config_files"
        pattern: "\\.(env|config|ini|conf)$"
        action: "require_confirmation"
        severity: "high"
        
      - name: "block_network_tools"
        pattern: "(nc|netcat|nmap|masscan)"
        action: "deny"
        severity: "critical"
  
  sandbox:
    provider: "docker"  # docker, firejail, subprocess
    image: "python:3.11-slim"
    memory_limit: "512m"
    cpu_limit: "1.0"
    network_access: false
    mount_points:
      - "./workspace:/workspace:rw"
      - "/tmp:/tmp:rw"
  
  human_loop:
    enabled: true
    auto_approve_safe: true
    confirmation_timeout: 60
    require_approval_for:
      - "system_commands"
      - "file_write"
      - "package_install"
```

## Soluci√≥n de Problemas Comunes

### Error: "No module named 'langchain'"
```bash
# Verificar que el entorno virtual est√° activado
which python  # Debe apuntar a venv/bin/python

# Reinstalar dependencias
pip install --force-reinstall -r requirements.txt
```

### Error: "ChromaDB initialization failed"
```bash
# Limpiar base de datos corrupta
rm -rf data/vector_db/*

# Reinstalar ChromaDB
pip uninstall chromadb
pip install chromadb
```

### Error: "OpenAI API key not found"
```bash
# Verificar que .env existe y tiene la clave
cat .env | grep OPENAI_API_KEY

# Verificar que se est√° cargando
python -c "
import os
from dotenv import load_dotenv
load_dotenv()
print('API Key:', os.getenv('OPENAI_API_KEY', 'NO ENCONTRADA'))
"
```

### Error: "Permission denied" en comandos del sistema
```bash
# Verificar permisos del directorio
ls -la data/

# Cambiar permisos si es necesario
chmod -R 755 data/

# En Windows, ejecutar como administrador si es necesario
```

### Problemas de Rendimiento
```bash
# Verificar uso de recursos
python -c "
import psutil
print(f'CPU: {psutil.cpu_percent()}%')
print(f'RAM: {psutil.virtual_memory().percent}%')
print(f'Disco: {psutil.disk_usage(\"/\").percent}%')
"

# Limpiar cach√© si es necesario
rm -rf data/cache/*
```

## Configuraci√≥n para Desarrollo

### Setup de Desarrollo
```bash
# Instalar dependencias de desarrollo
pip install -r requirements-dev.txt

# Configurar pre-commit hooks
pre-commit install

# Ejecutar tests
pytest tests/ -v

# Verificar calidad de c√≥digo
black local_agent/
flake8 local_agent/
mypy local_agent/
```

### Variables de Entorno para Desarrollo
```bash
# .env.development
DEBUG_MODE=true
AUTO_RELOAD=true
LOG_LEVEL=DEBUG
ENABLE_PROMETHEUS=true
ENABLE_WEB_UI=true

# Configuraci√≥n de testing
TEST_DIRECTORY=./tests
ENABLE_TEST_SANDBOX=true
TEST_TIMEOUT=30
```

## Configuraci√≥n para Producci√≥n

### Optimizaciones de Producci√≥n
```bash
# .env.production
DEBUG_MODE=false
LOG_LEVEL=WARNING
ENABLE_COMPRESSION=true
MAX_WORKERS=8
CONNECTION_POOL_SIZE=20

# Configuraci√≥n de seguridad estricta
STRICT_GUARDRAILS=true
REQUIRE_CONFIRMATION=true
ENABLE_AUDIT_LOGGING=true

# Configuraci√≥n de backup
ENABLE_AUTO_BACKUP=true
BACKUP_INTERVAL=6
MAX_BACKUPS=30
```

### Deployment con Docker
```bash
# Construir imagen optimizada
docker build -f Dockerfile.prod -t local-agent:prod .

# Ejecutar en producci√≥n
docker run -d \
  --name local-agent-prod \
  --restart unless-stopped \
  -p 8000:8000 \
  -v /opt/agent/data:/app/data \
  -v /opt/agent/logs:/app/logs \
  --memory=2g \
  --cpus=2 \
  local-agent:prod
```

## Verificaci√≥n Final

### Checklist de Instalaci√≥n
- [ ] Python 3.8+ instalado
- [ ] Dependencias instaladas sin errores
- [ ] Archivo .env configurado con API keys
- [ ] Directorios de datos creados
- [ ] Base de datos vectorial inicializada
- [ ] Herramientas b√°sicas funcionando
- [ ] Interfaz CLI accesible
- [ ] Logs gener√°ndose correctamente

### Test de Funcionalidad Completa
```bash
# Ejecutar suite de tests completa
python examples/complete_example.py

# Deber√≠a mostrar:
# ‚úÖ Demo: Uso B√°sico del Agente Local
# ‚úÖ Demo: Herramientas Personalizadas  
# ‚úÖ Demo: Memoria y Contexto
# ‚úÖ Demo: Seguridad y Guardrails
# ‚úÖ Demo: Ejecuci√≥n Paralela
# üéâ Todas las demostraciones completadas exitosamente!
```
