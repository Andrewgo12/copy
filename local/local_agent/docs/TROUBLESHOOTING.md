# Gu√≠a de Soluci√≥n de Problemas

## Problemas de Instalaci√≥n

### Error: "Python version not supported"
**S√≠ntoma**: Error durante instalaci√≥n sobre versi√≥n de Python
**Causa**: Python < 3.8
**Soluci√≥n**:
```bash
# Verificar versi√≥n actual
python --version

# Instalar Python 3.11 (recomendado)
# Ubuntu/Debian:
sudo apt update
sudo apt install python3.11 python3.11-venv

# macOS con Homebrew:
brew install python@3.11

# Windows: Descargar desde python.org
```

### Error: "pip install failed"
**S√≠ntoma**: Falla instalaci√≥n de dependencias
**Causa**: Problemas de red, permisos o dependencias del sistema
**Soluci√≥n**:
```bash
# Actualizar pip
python -m pip install --upgrade pip

# Instalar con verbose para ver detalles
pip install -r requirements.txt -v

# Si falla una dependencia espec√≠fica:
pip install --no-deps nombre-paquete

# En sistemas Linux, instalar dependencias del sistema:
sudo apt install build-essential python3-dev
```

### Error: "ChromaDB initialization failed"
**S√≠ntoma**: Error al inicializar base de datos vectorial
**Causa**: Permisos de directorio o dependencias faltantes
**Soluci√≥n**:
```bash
# Limpiar directorio de base de datos
rm -rf data/vector_db/*

# Verificar permisos
chmod -R 755 data/

# Reinstalar ChromaDB
pip uninstall chromadb
pip install chromadb

# En Windows, ejecutar como administrador si es necesario
```

## Problemas de Configuraci√≥n

### Error: "API key not found"
**S√≠ntoma**: Error sobre clave API faltante
**Causa**: Archivo .env mal configurado
**Soluci√≥n**:
```bash
# Verificar que .env existe
ls -la .env

# Verificar contenido
cat .env | grep API_KEY

# Formato correcto:
OPENAI_API_KEY=sk-tu-clave-real-aqui
# NO usar comillas, espacios extra, etc.

# Verificar que se carga correctamente:
python -c "
import os
from dotenv import load_dotenv
load_dotenv()
print('OpenAI:', 'CONFIGURADA' if os.getenv('OPENAI_API_KEY') else 'FALTANTE')
"
```

### Error: "Permission denied" en operaciones de archivos
**S√≠ntoma**: No puede leer/escribir archivos
**Causa**: Permisos insuficientes
**Soluci√≥n**:
```bash
# Verificar permisos del directorio actual
ls -la

# Cambiar permisos si es necesario
chmod -R 755 .

# En Windows, verificar que no est√° en directorio protegido
# Mover proyecto a Documents/ o Desktop/

# Verificar que no hay antivirus bloqueando
```

## Problemas de Ejecuci√≥n

### Error: "Tool execution timeout"
**S√≠ntoma**: Herramientas fallan por timeout
**Causa**: Operaciones muy lentas o configuraci√≥n incorrecta
**Soluci√≥n**:
```bash
# Aumentar timeout en .env
MAX_EXECUTION_TIME=600

# Verificar recursos del sistema
python -c "
import psutil
print(f'CPU: {psutil.cpu_percent()}%')
print(f'RAM: {psutil.virtual_memory().percent}%')
print(f'Disco: {psutil.disk_usage(\".\").percent}%')
"

# Si recursos est√°n altos, cerrar aplicaciones innecesarias
```

### Error: "LLM connection failed"
**S√≠ntoma**: No puede conectar con el modelo LLM
**Causa**: Problemas de red, API key inv√°lida, o l√≠mites de rate
**Soluci√≥n**:
```bash
# Verificar conectividad
curl -I https://api.openai.com/v1/models

# Verificar API key
curl -H "Authorization: Bearer $OPENAI_API_KEY" \
     https://api.openai.com/v1/models

# Verificar l√≠mites de rate en dashboard de OpenAI
# Esperar si has excedido l√≠mites

# Cambiar a modelo m√°s barato temporalmente:
LLM_MODEL=gpt-3.5-turbo
```

### Error: "Memory storage failed"
**S√≠ntoma**: Error guardando en memoria
**Causa**: Base de datos corrupta o espacio insuficiente
**Soluci√≥n**:
```bash
# Verificar espacio en disco
df -h .

# Limpiar memoria corrupta
rm -rf data/vector_db/*
rm -rf data/cache/*

# Reinicializar base de datos
python -c "
from storage.vector_db import VectorDatabase
db = VectorDatabase()
print('‚úÖ Base de datos reinicializada')
"
```

## Problemas de Rendimiento

### Agente muy lento
**S√≠ntomas**: Respuestas tardan mucho tiempo
**Diagn√≥stico**:
```bash
# Verificar logs para identificar cuellos de botella
tail -f data/logs/agent.log

# Verificar uso de recursos
top  # Linux/macOS
# o
taskmgr  # Windows
```

**Soluciones**:
```bash
# 1. Reducir contexto m√°ximo
echo "MAX_CONTEXT_ITEMS=10" >> .env

# 2. Deshabilitar memoria si no es necesaria
echo "ENABLE_MEMORY=false" >> .env

# 3. Usar modelo m√°s r√°pido
echo "LLM_MODEL=gpt-3.5-turbo" >> .env

# 4. Aumentar workers
echo "MAX_WORKERS=2" >> .env

# 5. Limpiar cach√©
rm -rf data/cache/*
```

### Memoria RAM alta
**S√≠ntomas**: Agente consume mucha memoria
**Soluciones**:
```bash
# Reducir memoria a corto plazo
echo "MAX_SHORT_TERM_MEMORY=50" >> .env

# Limpiar memoria vectorial antigua
python -c "
from storage.vector_db import VectorDatabase
db = VectorDatabase()
# Implementar limpieza de documentos antiguos
"

# Reiniciar agente peri√≥dicamente
```

## Problemas de Seguridad

### Guardrails muy restrictivos
**S√≠ntoma**: Muchas acciones bloqueadas
**Soluci√≥n**:
```bash
# Revisar reglas activas
python -c "
from safety.guardrails import SafetyGuardrails
from core.agent import AgentConfig
config = AgentConfig()
safety = SafetyGuardrails(config)
rules = safety.list_rules()
for rule in rules:
    print(f'{rule[\"name\"]}: {rule[\"severity\"]}')
"

# Deshabilitar regla espec√≠fica (temporal)
# En el c√≥digo, a√±adir:
# safety.disable_rule("nombre_regla")

# O modificar configuraci√≥n
echo "STRICT_GUARDRAILS=false" >> .env
```

### Sandbox no funciona
**S√≠ntoma**: Comandos del sistema fallan
**Causa**: Docker no disponible o mal configurado
**Soluci√≥n**:
```bash
# Verificar Docker
docker --version
docker ps

# Si Docker no est√° disponible, deshabilitar sandbox
echo "ENABLE_SANDBOX=false" >> .env

# ‚ö†Ô∏è ADVERTENCIA: Solo para desarrollo/testing
# En producci√≥n, usar siempre sandbox
```

## Problemas Espec√≠ficos por SO

### Windows

#### Error: "venv\Scripts\activate no reconocido"
```powershell
# Cambiar pol√≠tica de ejecuci√≥n
Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser

# O usar activaci√≥n alternativa
venv\Scripts\Activate.ps1
```

#### Error: "Microsoft Visual C++ required"
```bash
# Instalar Build Tools para Visual Studio
# Descargar desde: https://visualstudio.microsoft.com/visual-cpp-build-tools/

# O instalar paquetes precompilados
pip install --only-binary=all -r requirements.txt
```

### macOS

#### Error: "Command Line Tools not found"
```bash
# Instalar Xcode Command Line Tools
xcode-select --install

# Verificar instalaci√≥n
xcode-select -p
```

#### Error: "Permission denied" en /usr/local
```bash
# Usar Homebrew para gesti√≥n de paquetes
/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"

# Instalar Python con Homebrew
brew install python@3.11
```

### Linux

#### Error: "python3-venv not found"
```bash
# Ubuntu/Debian
sudo apt update
sudo apt install python3-venv python3-pip

# CentOS/RHEL
sudo yum install python3-venv python3-pip

# Arch Linux
sudo pacman -S python-virtualenv python-pip
```

#### Error: "gcc not found"
```bash
# Ubuntu/Debian
sudo apt install build-essential

# CentOS/RHEL
sudo yum groupinstall "Development Tools"

# Arch Linux
sudo pacman -S base-devel
```

## Herramientas de Diagn√≥stico

### Script de Diagn√≥stico Autom√°tico
```python
# diagnostics.py
import sys
import subprocess
import platform
from pathlib import Path

def run_diagnostics():
    """Ejecuta diagn√≥sticos completos del sistema"""
    
    print("üîç DIAGN√ìSTICO DEL SISTEMA")
    print("=" * 40)
    
    # Sistema operativo
    print(f"OS: {platform.system()} {platform.release()}")
    print(f"Python: {sys.version}")
    
    # Verificar archivos cr√≠ticos
    critical_files = [
        "requirements.txt", "main.py", ".env", 
        "core/agent.py", "tools/base.py"
    ]
    
    print("\nüìÅ Archivos cr√≠ticos:")
    for file in critical_files:
        exists = "‚úÖ" if Path(file).exists() else "‚ùå"
        print(f"  {exists} {file}")
    
    # Verificar dependencias
    print("\nüì¶ Dependencias:")
    dependencies = [
        "langchain", "chromadb", "fastapi", 
        "openai", "anthropic", "rich"
    ]
    
    for dep in dependencies:
        try:
            __import__(dep)
            print(f"  ‚úÖ {dep}")
        except ImportError:
            print(f"  ‚ùå {dep}")
    
    # Verificar configuraci√≥n
    print("\n‚öôÔ∏è Configuraci√≥n:")
    try:
        from dotenv import load_dotenv
        import os
        load_dotenv()
        
        configs = [
            ("OPENAI_API_KEY", bool(os.getenv("OPENAI_API_KEY"))),
            ("VECTOR_DB_PATH", Path(os.getenv("VECTOR_DB_PATH", "")).exists()),
            ("LOG_LEVEL", bool(os.getenv("LOG_LEVEL")))
        ]
        
        for config, status in configs:
            status_icon = "‚úÖ" if status else "‚ùå"
            print(f"  {status_icon} {config}")
            
    except Exception as e:
        print(f"  ‚ùå Error cargando configuraci√≥n: {e}")

if __name__ == "__main__":
    run_diagnostics()
```

### Verificaci√≥n de Conectividad
```python
# test_connectivity.py
import asyncio
import aiohttp
import os
from dotenv import load_dotenv

async def test_api_connectivity():
    """Prueba conectividad con APIs externas"""
    load_dotenv()
    
    tests = []
    
    # Test OpenAI
    openai_key = os.getenv("OPENAI_API_KEY")
    if openai_key:
        try:
            async with aiohttp.ClientSession() as session:
                headers = {"Authorization": f"Bearer {openai_key}"}
                async with session.get(
                    "https://api.openai.com/v1/models",
                    headers=headers,
                    timeout=10
                ) as response:
                    if response.status == 200:
                        tests.append("‚úÖ OpenAI API - Conectado")
                    else:
                        tests.append(f"‚ùå OpenAI API - Error {response.status}")
        except Exception as e:
            tests.append(f"‚ùå OpenAI API - Error: {e}")
    else:
        tests.append("‚ö†Ô∏è OpenAI API - No configurada")
    
    # Test conectividad general
    try:
        async with aiohttp.ClientSession() as session:
            async with session.get("https://httpbin.org/ip", timeout=5) as response:
                if response.status == 200:
                    tests.append("‚úÖ Conectividad Internet - OK")
                else:
                    tests.append("‚ùå Conectividad Internet - Problemas")
    except Exception as e:
        tests.append(f"‚ùå Conectividad Internet - Error: {e}")
    
    return tests

# Ejecutar tests
if __name__ == "__main__":
    results = asyncio.run(test_api_connectivity())
    for result in results:
        print(result)
```

## Logs y Debugging

### Habilitar Logging Detallado
```bash
# En .env
LOG_LEVEL=DEBUG
ENABLE_TOOL_LOGGING=true

# Ver logs en tiempo real
tail -f data/logs/agent.log

# En Windows
Get-Content data\logs\agent.log -Wait
```

### Interpretar Logs Comunes
```
# Log normal de ejecuci√≥n
2024-01-15 10:30:15 | INFO | core.agent:process_request:45 - Procesando solicitud del usuario
2024-01-15 10:30:15 | DEBUG | core.planner:create_plan:78 - Plan creado: 3 acciones
2024-01-15 10:30:16 | INFO | core.executor:execute_plan:123 - Ejecutando plan: uuid-here

# Error de herramienta
2024-01-15 10:30:17 | ERROR | tools.file_tools:execute:89 - Error leyendo archivo: Permission denied

# Violaci√≥n de guardrails
2024-01-15 10:30:18 | WARNING | safety.guardrails:evaluate_action:156 - Violaci√≥n: comando peligroso detectado
```

### Debug Interactivo
```python
# A√±adir breakpoints en el c√≥digo
import pdb; pdb.set_trace()

# O usar debugger moderno
import ipdb; ipdb.set_trace()

# Ejecutar con debugger
python -m pdb main.py
```

## Problemas de Rendimiento

### Optimizaci√≥n de Memoria
```python
# memory_optimizer.py
import gc
import psutil
from storage.vector_db import VectorDatabase

async def optimize_memory():
    """Optimiza uso de memoria del agente"""
    
    # 1. Limpiar cach√© de archivos
    from core.context import ContextEngine
    context_engine = ContextEngine(None)
    context_engine.file_cache.clear()
    
    # 2. Compactar base de datos vectorial
    db = VectorDatabase()
    # Implementar compactaci√≥n
    
    # 3. Forzar garbage collection
    gc.collect()
    
    # 4. Mostrar uso actual
    memory = psutil.virtual_memory()
    print(f"Memoria usada: {memory.percent}%")
    print(f"Memoria disponible: {memory.available / 1024**3:.1f}GB")

if __name__ == "__main__":
    import asyncio
    asyncio.run(optimize_memory())
```

### Optimizaci√≥n de Velocidad
```bash
# Configuraciones para mejor rendimiento
echo "MAX_CONTEXT_ITEMS=5" >> .env
echo "MEMORY_IMPORTANCE_THRESHOLD=0.5" >> .env
echo "MAX_SHORT_TERM_MEMORY=25" >> .env
echo "ENABLE_COMPRESSION=true" >> .env
```

## Problemas de Seguridad

### Sandbox no funciona en Windows
```bash
# Alternativa: usar subprocess con restricciones
echo "ENABLE_SANDBOX=false" >> .env
echo "SANDBOX_PROVIDER=subprocess" >> .env

# ‚ö†Ô∏è Menos seguro, solo para desarrollo
```

### Comandos bloqueados incorrectamente
```python
# Modificar guardrails temporalmente
from safety.guardrails import SafetyGuardrails

# En core/agent.py, despu√©s de crear safety:
# safety.disable_rule("nombre_regla_especifica")

# O crear regla personalizada menos restrictiva
custom_rule = GuardrailRule(
    name="allow_my_command",
    pattern="mi_comando_especifico",
    action=ActionDecision.ALLOW,
    applies_to=["system_command"],
    severity="low",
    message="Comando personalizado permitido"
)
safety.add_custom_rule(custom_rule)
```

## Recuperaci√≥n de Datos

### Backup de Memoria
```python
# backup_memory.py
import asyncio
from storage.vector_db import VectorDatabase

async def backup_all_memory():
    """Crea backup completo de la memoria"""
    db = VectorDatabase()
    
    collections = ["conversations", "code_context", "web_knowledge"]
    
    for collection in collections:
        backup_file = f"backup_{collection}_{int(time.time())}.json"
        success = await db.backup_collection(collection, backup_file)
        print(f"Backup {collection}: {'‚úÖ' if success else '‚ùå'}")

asyncio.run(backup_all_memory())
```

### Restaurar desde Backup
```python
# restore_memory.py
import asyncio
import json
from storage.vector_db import VectorDatabase

async def restore_from_backup(backup_file):
    """Restaura memoria desde backup"""
    db = VectorDatabase()
    
    with open(backup_file, 'r') as f:
        backup_data = json.load(f)
    
    collection_name = backup_data["collection_name"]
    
    # Limpiar colecci√≥n actual
    await db.clear_collection(collection_name)
    
    # Restaurar documentos
    collection = db.collections[collection_name]
    collection.add(
        documents=backup_data["documents"],
        metadatas=backup_data["metadatas"],
        ids=backup_data["ids"]
    )
    
    print(f"‚úÖ Memoria restaurada: {collection_name}")

# Uso: asyncio.run(restore_from_backup("backup_conversations_123456.json"))
```

## Contacto y Soporte

### Informaci√≥n de Debug para Reportes
```bash
# Generar reporte de debug completo
python -c "
import sys, platform, subprocess
print('=== REPORTE DE DEBUG ===')
print(f'Python: {sys.version}')
print(f'OS: {platform.platform()}')
print(f'Directorio: {os.getcwd()}')

# Versiones de dependencias clave
deps = ['langchain', 'chromadb', 'fastapi', 'openai']
for dep in deps:
    try:
        mod = __import__(dep)
        version = getattr(mod, '__version__', 'unknown')
        print(f'{dep}: {version}')
    except ImportError:
        print(f'{dep}: NOT INSTALLED')

print('========================')
"
```

### Logs para Soporte
```bash
# Crear paquete de logs para soporte
tar -czf debug_logs.tar.gz data/logs/ .env config/

# En Windows
powershell Compress-Archive -Path data\logs\,config\ -DestinationPath debug_logs.zip
```

**Al reportar problemas, incluye:**
1. Reporte de debug completo
2. Logs relevantes (√∫ltimas 100 l√≠neas)
3. Pasos exactos para reproducir
4. Configuraci√≥n (sin API keys)
5. Mensaje de error completo
